<think>
Okay, so I need to show that for a nonzero integer a, the greatest common divisor (gcd) of a and 0 is |a|, the gcd of a and a is |a|, and the gcd of a and 1 is 1. Let me start by recalling what the gcd means. The gcd of two integers is the largest positive integer that divides both of them without leaving a remainder. 

First, let me tackle gcd(a, 0). Hmm, I remember that the gcd is defined for two integers, but when one of them is zero, there's a special case. Wait, I think the definition says that the gcd of a and 0 is the absolute value of a. But why is that? Let me think. 

If I have two numbers, say a and 0. The divisors of 0 are all integers because any integer divides 0. But the divisors of a are the integers that divide a. So the common divisors of a and 0 would be the divisors of a. But the greatest common divisor would be the greatest divisor of a, which is |a|. Because the divisors of a are ±1, ±a, etc., but the greatest one is |a|. Therefore, gcd(a, 0) should be |a|. That makes sense. But let me check with an example. Suppose a is 5. Then gcd(5, 0) should be 5. Since 5 divides 5 and 5 divides 0, and there's no larger number than 5 that divides 5. Similarly, if a is -3, then gcd(-3, 0) is 3, which is |a|. So that seems to hold. So I think that's the first part done.

Next, gcd(a, a). Well, the gcd of a number with itself. Well, the divisors of a and a are the same, so the greatest common divisor is the number itself. But since gcd is always positive, it should be |a|. For example, if a is 6, then gcd(6,6) is 6. If a is -4, then gcd(-4, -4) is 4. So yes, that seems right. Because the greatest common divisor of a number with itself is the number itself, but since gcd is defined as a positive integer, it's the absolute value. So that's the second part.

Third, gcd(a, 1). Well, the divisors of 1 are only 1 and -1. So the common divisors of a and 1 would be the divisors that divide both a and 1. But since 1 divides every integer, the common divisors are the divisors of 1. Therefore, the greatest common divisor is 1. For example, if a is 7, then gcd(7,1) is 1. If a is -2, gcd(-2, 1) is 1. So that's the third part.

But wait, maybe I should verify this more formally. Let me think about the definition of gcd. The gcd of two integers a and b is the largest positive integer that divides both a and b. So for gcd(a, 0), since 0 is divisible by any integer, the divisors of 0 are all integers. Therefore, the common divisors of a and 0 are the divisors of a. The largest positive divisor of a is |a|. Hence, gcd(a, 0) = |a|.

For gcd(a, a), the common divisors of a and a are the divisors of a. The largest positive divisor is |a|. Therefore, gcd(a, a) = |a|.

For gcd(a, 1), since 1 is only divisible by 1 and -1. Therefore, the common divisors of a and 1 are the divisors of 1, which are 1 and -1. The largest positive one is 1. Hence, gcd(a, 1) = 1.

But maybe I need to recall the Euclidean algorithm here. The Euclidean algorithm says that gcd(a, b) = gcd(b, a mod b). But when b is 0, then gcd(a, 0) is |a|. So that's another way to see it. For example, if we apply the Euclidean algorithm to a and 0, since 0 mod a is 0, then gcd(a, 0) = gcd(0, 0). Wait, but that seems like a problem. Wait, actually, the Euclidean algorithm is usually defined for positive integers, but let me check.

Actually, the Euclidean algorithm is typically applied to positive integers, but the gcd is always positive. So if we have gcd(a, 0), then since 0 is divisible by a, the gcd is |a|. So that's consistent with the Euclidean algorithm. For example, if you have gcd(6, 0), then according to the algorithm, it's |6| = 6. Similarly, if you have gcd(-6, 0), it's | -6 | = 6.

For gcd(a, a), using the Euclidean algorithm: gcd(a, a) = gcd(a, a mod a). But a mod a is 0, so gcd(a, 0) which is |a|. So that gives the same result.

For gcd(a, 1), using the Euclidean algorithm: gcd(a, 1) = gcd(1, a mod 1). But a mod 1 is 0, so gcd(1, 0) which is 1. Hence, that also gives the result.

So that seems to confirm the three results.

But maybe I should also think about the definition of gcd in terms of linear combinations. The gcd of two integers is the smallest positive integer that can be expressed as a linear combination of the two. So for gcd(a, 0), since 0 can be expressed as 0*a + 0*0, but maybe that's not helpful. Wait, more accurately, the gcd is the smallest positive integer that can be written as ma + 0n for integers m, n. But since 0n is 0, then ma is the combination. So the smallest positive integer that is a multiple of a. That would be |a|. Therefore, gcd(a, 0) = |a|.

Similarly, for gcd(a, a), the linear combinations are ma + na. The smallest positive integer that can be expressed as ma + na. But since a and a are the same, this is the same as the gcd of a and a, which is |a|.

For gcd(a, 1), the linear combinations are ma + n*1. The smallest positive integer that can be expressed as such. But since 1 is 1, and any integer can be expressed as a combination. But the smallest positive is 1. Hence, gcd(a, 1) = 1.

Alternatively, since 1 divides every integer, the gcd must be 1.

But maybe I should also recall that gcd(a, b) is the same as gcd(|a|, |b|). So since we are dealing with integers, we can take absolute values. Therefore, gcd(a, 0) is gcd(|a|, 0) which is |a|, since gcd(|a|, 0) is |a|. Similarly, gcd(a, a) is gcd(|a|, |a|) which is |a|. And gcd(a, 1) is gcd(|a|, 1) which is 1, since 1 is the gcd of any number and 1.

So that also confirms the results.

But maybe I need to check some edge cases. Let me take a = 1. Then gcd(1, 0) is 1, which is |1|. gcd(1, 1) is 1, which is |1|. gcd(1, 1) is 1. So that works. If a = -3, then gcd(-3, 0) is 3, which is |-3|. gcd(-3, -3) is 3, which is |-3|. gcd(-3, 1) is 1. So that works.

Another example: a = 0? Wait, but the problem says a is a nonzero integer. So a can't be zero. So that's okay.

Another example: a = 2. gcd(2, 0) is 2, gcd(2, 2) is 2, gcd(2, 1) is 1. Correct.

Another example: a = -5. gcd(-5, 0) is 5, gcd(-5, -5) is 5, gcd(-5, 1) is 1. Correct.

Therefore, all the cases check out. Therefore, the three statements are proven.

But maybe I need to write this more formally, using definitions and properties.

Starting with gcd(a, 0). Let me recall that the gcd is the greatest common divisor, which is the largest positive integer that divides both numbers. Since 0 is divisible by any integer, the common divisors of a and 0 are exactly the divisors of a. The greatest positive divisor of a is |a|. Therefore, gcd(a, 0) = |a|.

For gcd(a, a). The common divisors of a and a are the divisors of a. Hence, the greatest common divisor is the greatest divisor of a, which is |a|.

For gcd(a, 1). The divisors of 1 are 1 and -1. Since 1 divides every integer, the common divisors of a and 1 are 1 and -1. The greatest positive common divisor is 1. Therefore, gcd(a, 1) = 1.

Alternatively, using the Euclidean algorithm:

gcd(a, 0) = |a|, because in the Euclidean algorithm, when you have gcd(a, 0), you just return |a|.

gcd(a, a) = gcd(a, 0) = |a|.

gcd(a, 1) = gcd(1, a mod 1) = gcd(1, 0) = 1.

Therefore, using the Euclidean algorithm, we can also derive the results.

Alternatively, using the property that gcd(a, b) = gcd(b, a) and gcd(a, 0) = |a|.

But maybe I should also think about the definition of gcd in terms of the set of common divisors. The gcd is the greatest element in the set of common divisors. So for gcd(a, 0), the common divisors are the divisors of a. The maximum is |a|. For gcd(a, a), the common divisors are the divisors of a, so again maximum is |a|. For gcd(a, 1), the common divisors are the divisors of 1, which are 1 and -1, so maximum is 1.

Therefore, all three results follow from the definition.

I think that covers all the bases. Therefore, I can conclude that for a nonzero integer a, gcd(a, 0) = |a|, gcd(a, a) = |a|, and gcd(a, 1) = 1.

**Final Answer**
For a nonzero integer $ a $, we have $\gcd(a, 0) = \boxed{|a|}$, $\gcd(a, a) = \boxed{|a|}$, and $\gcd(a, 1) = \boxed{1}$.
</think>

To establish the truth of the three statements regarding the greatest common divisor (gcd) for a nonzero integer $ a $, we proceed by analyzing each case using the definition and properties of the gcd.

---

### 1. **$ \gcd(a, 0) = |a| $**

The gcd of two integers is the largest positive integer that divides both of them without a remainder.

- The number 0 is divisible by any integer, so the set of common divisors of $ a $ and 0 is the same as the set of divisors of $ a $.
- The largest positive divisor of any nonzero integer $ a $ is $ |a| $.
- Therefore, the greatest common divisor of $ a $ and 0 is $ |a| $.

**Conclusion**:  
$$
\gcd(a, 0) = \boxed{|a|}
$$

---

### 2. **$ \gcd(a, a) = |a| $**

- The gcd of a number with itself is the number itself, since it is the largest positive integer that divides $ a $.
- However, gcd is defined to be a **positive** integer, so the result is the **absolute value** of $ a $.
- For example, $ \gcd(5, 5) = 5 $, and $ \gcd(-5, -5) = 5 $, which is $ |a| $.

**Conclusion**:  
$$
\gcd(a, a) = \boxed{|a|}
$$

---

### 3. **$ \gcd(a, 1) = 1 $**

- The number 1 has only two divisors: 1 and -1.
- Since 1 divides every integer, the common divisors of $ a $ and 1 are exactly the divisors of 1.
- Therefore, the greatest common divisor is 1.

**Conclusion**:  
$$
\gcd(a, 1) = \boxed{1}
$$

---

### Final Answer

For a nonzero integer $ a $, we have:

$$
\gcd(a, 0) = \boxed{|a|}, \quad \gcd(a, a) = \boxed{|a|}, \quad \gcd(a, 1) = \boxed{1}
$$